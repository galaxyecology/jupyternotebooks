{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-bahrain",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Author: Arthur BARREAU\n",
    "# Date: 2025-05-12\n",
    "# R version: 4.3.3\n",
    "# Description: This script generates monthly mean sea ice concentration maps (left column)\n",
    "#              and associated anomalies (right column), using satellite data from the\n",
    "#              National Snow and Ice Data Center (NSIDC). The pink line represents the\n",
    "#              median sea ice extent during the reference period 1981–2010.\n",
    "# Source: https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/geotiff/\n",
    "\n",
    "# ==============================================================================\n",
    "# 0. PACKAGE & LIBRARY INSTALLATION ----\n",
    "# ==============================================================================\n",
    "\n",
    "options(timeout=3600)\n",
    "system(\"conda install -y r-sf=1.0_20 r-terra=1.8_42 r-fields r-magick\")\n",
    "system(\"cp /opt/conda/pkgs/proj-9.6.0-h0054346_1/share/proj/proj.db /opt/conda/envs/rlang-kernel/share/proj/proj.db\")\n",
    "\n",
    "library(terra)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "library(RColorBrewer)\n",
    "library(sf)\n",
    "library(jsonlite) \n",
    "library(fields)\n",
    "library(magick)\n",
    "\n",
    "# ==============================================================================\n",
    "# 1. VARIABLES ----\n",
    "# ==============================================================================\n",
    "\n",
    "json_data <- fromJSON(\"galaxy_inputs/galaxy_inputs.json\")\n",
    "\n",
    "start_month      <- json_data$month\n",
    "start_year       <- json_data$year\n",
    "chose            <- json_data$ConcentrationXandXorXAnomalies\n",
    "asd_show         <- json_data$ASD\n",
    "subarea          <- json_data$subarea\n",
    "month_list       <- trimws(unlist(strsplit(start_month, \",\")))\n",
    "year_list        <- trimws(unlist(strsplit(start_year, \",\")))\n",
    "chose_list       <- trimws(unlist(strsplit(chose, \"_\")))\n",
    "area_list        <- trimws(unlist(strsplit(subarea, \",\")))\n",
    "m                <- json_data$multiplier\n",
    "text_title       <- json_data$title\n",
    "legend_chose     <- json_data$legendXchose\n",
    "bbox             <- json_data$bbox\n",
    "year_ano         <- json_data$yearXanomaly\n",
    "png              <- json_data$png\n",
    "# ==============================================================================\n",
    "# 2. VARIABLES ----\n",
    "# ==============================================================================\n",
    "\n",
    "months_days <- list(\n",
    "  Jan = 31, Feb = 28, Mar = 31, Apr = 30, May = 31, Jun = 30, \n",
    "  Jul = 31, Aug = 31, Sep = 30, Oct = 31, Nov = 30, Dec = 31\n",
    ")\n",
    "\n",
    "# ==============================================================================\n",
    "# 3.1 FUNCTIONS ----\n",
    "# ==============================================================================\n",
    "\n",
    "# Create directories for storing TIFF and Shapefile data\n",
    "create_directories <- function(year, month) {\n",
    "  tif_path <- sprintf(\"%s_%s_tif_folder\", year,month)\n",
    "  zip_path <- sprintf(\"%s_%s_zip_folder\", year,month)\n",
    "  shp_path <- sprintf(\"%s_%s_shapefile_folder\", year,month)\n",
    "  tif_mean_path <- sprintf(\"%s_%s_folder_tif_1981_2010\", year,month)\n",
    "  dir.create(tif_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  dir.create(zip_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  dir.create(shp_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  dir.create(tif_mean_path, showWarnings = FALSE, recursive = TRUE)\n",
    "  return(list(tif_path = tif_path, zip_path = zip_path, shp_path = shp_path, tif_mean_path=tif_mean_path))\n",
    "}\n",
    "\n",
    "# Download daily TIFF files\n",
    "download_tiff_files <- function(path, year, start_month, month_index) {\n",
    "  month_index <- match(start_month, names(months_days))  \n",
    "  month_folder <- sprintf(\"%02d_%s\", month_index, start_month) \n",
    "  \n",
    "  for (day in 1:months_days[[start_month]]) {\n",
    "    date_str <- sprintf(\"%s%02d%02d\", year, month_index, day)  \n",
    "    url <- paste0(\"https://noaadata.apps.nsidc.org/NOAA/G02135/south/daily/geotiff/\", year, \"/\", month_folder, \"/S_\", date_str, \"_concentration_v3.0.tif\")\n",
    "    destfile <- file.path(path, sprintf(\"S_%s_concentration.tif\", date_str))\n",
    "    tryCatch({\n",
    "      download.file(url, destfile)\n",
    "    },error=function(e){})\n",
    "    \n",
    "  }\n",
    "}\n",
    "\n",
    "\n",
    "# Compute the monthly mean raster\n",
    "compute_monthly_mean <- function(path, start_year, month_index) {\n",
    "  tif_files <- list.files(path, pattern = \"\\\\.tif$\", full.names = TRUE)\n",
    "  rasters <- rast(tif_files)\n",
    "  rasters[rasters == 2550] <- NA  # Remplacer les valeurs 2550 par NA\n",
    "  mean_raster <- mean(rasters, na.rm = TRUE)  \n",
    "  return(mean_raster)\n",
    "}\n",
    "\n",
    "\n",
    "# Download and process shapefiles\n",
    "download_shapefiles <- function(zip_path, shp_path, month_index) {\n",
    "  month_index <- sprintf(\"%02d\", month_index) \n",
    "  url <- paste0(\"https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/shapefiles/shp_median/median_extent_S_\",\n",
    "                month_index, \"_1981-2010_polyline_v3.0.zip\")\n",
    "  destfile <- file.path(zip_path, sprintf(\"median_extent_S_%s.zip\", month_index))\n",
    "  tryCatch({\n",
    "    download.file(url, destfile)\n",
    "    unzip(destfile, exdir = shp_path) \n",
    "  },error=function(e){})\n",
    "}\n",
    "\n",
    "# Merge shapefiles and compute mean polygon\n",
    "process_shapefiles <- function(shp_path) {\n",
    "  shp_files <- list.files(shp_path, pattern = \"\\\\.shp$\", full.names = TRUE)\n",
    "  polygons <- lapply(shp_files, st_read)\n",
    "  return(polygons)\n",
    "}\n",
    "\n",
    "download_tiff_1981_2010 <- function(path, start_year, end_year, month_index) {\n",
    "  month_index <- sprintf(\"%02d\", month_index) \n",
    "  base_url <- \"https://noaadata.apps.nsidc.org/NOAA/G02135/south/monthly/geotiff/\"\n",
    "  \n",
    "  months <- c(\"01_Jan\", \"02_Feb\", \"03_Mar\", \"04_Apr\", \"05_May\", \"06_Jun\",\n",
    "              \"07_Jul\", \"08_Aug\", \"09_Sep\", \"10_Oct\", \"11_Nov\", \"12_Dec\")\n",
    "  month_folder <- months[as.integer(month_index)]\n",
    "  \n",
    "  for (year in start_year:end_year) {\n",
    "    date_str <- sprintf(\"S_%s%s_concentration_v3.0.tif\", year, month_index)\n",
    "    url <- paste0(base_url, month_folder, \"/\", date_str)\n",
    "    destfile <- file.path(path, date_str)\n",
    "    tryCatch({\n",
    "      download.file(url, destfile, mode = \"wb\")\n",
    "    },error=function(e){})\n",
    "  }\n",
    "}\n",
    "\n",
    "compute_mean_raster_1981_2010 <- function(path,month_index) { \n",
    "  month_index <- sprintf(\"%02d\", month_index) \n",
    "  files <- list.files(path, pattern = \"\\\\.tif$\", full.names = TRUE)\n",
    "  rasters <- rast(files)\n",
    "  mean_raster_1981_2010 <- mean(rasters, na.rm = TRUE)  \n",
    "  return(mean_raster_1981_2010)\n",
    "}\n",
    "\n",
    "# Create color palettes and breaks for visualization\n",
    "create_colors_and_breaks <- function() {\n",
    "  breaks <- c(0,1, seq(150, 1000, by = 50),1050, 2531, 2541)\n",
    "  colors_glacier <- rev(c(\"#F7FCFF\", \"#E4F4FE\", \"#D0ECFE\", \"#BCE4FE\", \"#A8DCFD\",\n",
    "                          \"#94D5FD\", \"#7DCCFD\", \"#6AC4FC\", \"#57BCFC\", \"#45B4FC\",\n",
    "                          \"#31ABFC\", \"#23A3FC\", \"#1A9BFC\", \"#1994F9\", \"#178CF2\",\n",
    "                          \"#1684EB\", \"#137AE3\", \"#093C70\",\"#093C70\" ))\n",
    "  colors <- c(\n",
    "    rgb(9, 60, 112, maxColorValue = 255),\n",
    "    colors_glacier,  # Dégradé bleu glacier (1 à 1000)\n",
    "    rgb(0, 0, 0, maxColorValue = 255),      # Ligne côtière noire (2530)\n",
    "    rgb(119, 119, 119, maxColorValue = 255) # Terre grise (2540)\n",
    "  )\n",
    "  return(list(colors = colors, breaks = breaks))\n",
    "}\n",
    "\n",
    "# Visualization and saving results\n",
    "save_plot <- function(raster, colors, breaks, polygons, year, month,subareas_selected,area_list,title,ASD) {\n",
    "  plot(raster, col = colors, breaks = breaks, legend = FALSE, axes = FALSE, box = FALSE,mar = c(0, 0, 0, 0))\n",
    "  plot(st_geometry(polygons[[1]]), add = TRUE, pch = 21, col = 'red', cex = 1.5*m)\n",
    "  if(ASD){\n",
    "    plot(st_geometry(subareas_selected), add = TRUE, lwd = 1.5*m, border = 'red',mar=c(0,0,0,0))\n",
    "    zones <- st_read(\"asd/asd-shapefile-EPSG6932.shp\")  \n",
    "    zones_to_plot <- if (is.na(letters_only[1])) {area_list} else {default_areas}\n",
    "    zones <- zones %>% filter(GAR_Short_ %in% zones_to_plot) \n",
    "    centroids <- st_centroid(st_geometry(zones))\n",
    "    text(st_coordinates(centroids), labels = zones$GAR_Long_L, col = \"red\", cex = 0.8*m) \n",
    "  }\n",
    "  \n",
    "  \n",
    "  #add_labels(mode = 'auto', layer = 'ASDs', fontsize =1, col = 'red')\n",
    "  if(text_title != \"No Title\"){\n",
    "      if(text_title == \"Title in the Middle\"){\n",
    "        text(x = 350000, y = 150000, labels = sprintf(\"%s_%s\", year, month), cex = 3*m, font = 1, col=\"white\")\n",
    "          \n",
    "      }else{\n",
    "          text(x = 350000, y = 4000000, labels = sprintf(\"%s_%s\", year, month), cex = 3*m, font = 1,col=\"white\") \n",
    "      }\n",
    "  }  \n",
    "}\n",
    "\n",
    "# ==============================================================================\n",
    "# 3.2 ANOMALY ----\n",
    "# ==============================================================================\n",
    "\n",
    "filter_raster_values <- function(raster) {\n",
    "  raster[] <- ifelse(raster[] >= 1 & raster[] <= 150, 0, raster[])\n",
    "  return(raster)\n",
    "}\n",
    "\n",
    "compute_anomaly <- function(mean_raster, mean_1981_2010) {\n",
    "  mean_raster <- filter_raster_values(mean_raster)\n",
    "  mean_1981_2010 <- filter_raster_values(mean_1981_2010)\n",
    "  \n",
    "  anomaly <- mean_raster - mean_1981_2010\n",
    "  \n",
    "  minmax_value <- minmax(anomaly)\n",
    "  min_anomaly <- minmax_value[1]\n",
    "  max_anomaly <- minmax_value[2]\n",
    "  \n",
    "  breaks_neg <- seq(-500, -1, length.out = 11)  \n",
    "  breaks_pos <- seq(1, 500, length.out = 11) \n",
    "  breaks <- unique(c(min_anomaly, breaks_neg, breaks_pos, max_anomaly))\n",
    "  col_fun <- c(\"#053061\", \"#114781\", \"#1D5FA2\", \"#2B73B3\", \"#3A87BD\", \"#4F9BC7\", \"#71B0D3\", \n",
    "               \"#93C6DE\", \"#B1D5E7\", \"#CCE2EF\", \"#DEEBF2\", \"white\", \"#F8F1ED\", \"#FBE5D8\", \"#FCD7C2\", \n",
    "               \"#F8BFA4\", \"#F4A683\", \"#E8896C\", \"#DB6B55\", \"#CC4C44\", \"#BD2D35\", \"#A81529\", \n",
    "               \"#870A24\")\n",
    "  \n",
    "  return(list(anomaly = anomaly, breaks = breaks, col_fun = col_fun))\n",
    "}\n",
    "\n",
    "save_anomaly_plot <- function(anomaly_data,mean_raster, year, month,subareas_selected,area_list,ASD) {\n",
    "    plot(anomaly_data$anomaly, col = anomaly_data$col_fun, breaks = anomaly_data$breaks, legend = FALSE, axes = FALSE, box = FALSE, mar = c(0, 0, 0, 0))\n",
    "    plot(mean_raster, col = c(rgb(0, 0, 0, maxColorValue = 255),rgb(119, 119, 119, maxColorValue = 255)), breaks = c(2529,2531,2540),add=TRUE, legend = FALSE, axes = FALSE, box = FALSE)\n",
    "    if(ASD){\n",
    "    plot(st_geometry(subareas_selected), add = TRUE, lwd = 1.5*m, border = 'red',mar=c(0,0,0,0))\n",
    "    zones <- st_read(\"asd/asd-shapefile-EPSG6932.shp\")    \n",
    "    zones_to_plot <- if (is.na(letters_only[1])) {area_list} else {default_areas}\n",
    "    zones <- zones %>% filter(GAR_Short_ %in% zones_to_plot) \n",
    "    centroids <- st_centroid(st_geometry(zones))\n",
    "    text(st_coordinates(centroids), labels = zones$GAR_Long_L, col = \"red\", cex = 0.8*m)  # Ajouter les labels\n",
    "    }\n",
    "  \n",
    "    if(text_title != \"No Title\"){\n",
    "      if(text_title == \"Title in the Middle\"){\n",
    "          text(x = 350000, y = 150000, labels = sprintf(\"%s_%s\", year, month), cex = 3*m, font = 1, col=\"white\")\n",
    "      }else{\n",
    "          \n",
    "          text(x = 350000, y = 4000000, labels = sprintf(\"%s_%s\", year, month), cex = 3*m, font = 1) \n",
    "      }  \n",
    "  }  \n",
    "}\n",
    "\n",
    "mask_subarea <- function(area_list, raster, ASD) {\n",
    "    if (is.na(letters_only[1])) {\n",
    "        output_dir <- \"asd\"\n",
    "        dir.create(output_dir, showWarnings = FALSE)\n",
    "        base_url <- \"https://raw.githubusercontent.com/ccamlr/data/refs/tags/v0.5.0/geographical_data/asd/asd-shapefile-EPSG6932\"\n",
    "        extensions <- c(\".shp\", \".shx\", \".dbf\", \".prj\", \".cst\")\n",
    "        \n",
    "        urls_asd <- paste0(base_url, extensions)\n",
    "        destfiles <- file.path(output_dir, paste0(\"asd-shapefile-EPSG6932\", extensions))\n",
    "        \n",
    "        # Download each file and save to the output directory\n",
    "        for (i in seq_along(urls_asd)) {\n",
    "            download.file(urls_asd[i], destfiles[i], mode = \"wb\")\n",
    "        }\n",
    "        \n",
    "        ASD <- st_read(\"asd/asd-shapefile-EPSG6932.shp\", quiet = TRUE)\n",
    "        subareas_selected <- ASD %>% filter(GAR_Short_ %in% area_list)\n",
    "        \n",
    "        if(bbox){\n",
    "          subareas_bbox <- vect(st_as_sfc(st_bbox(subareas_selected)))\n",
    "          mask_mean_raster <- mask(crop(raster, subareas_bbox), subareas_bbox)\n",
    "        } else{\n",
    "            mask_mean_raster <- mask(crop(raster, vect(subareas_selected)), vect(subareas_selected))\n",
    "        }\n",
    "\n",
    "        # Preserve land and coast values\n",
    "        land_coast <- raster\n",
    "        land_coast[!(raster[] %in% c(2530, 2540))] <- NA  # Keep only pixels 2530 and 2540\n",
    "        land_coast_mask <- mask(crop(land_coast, ext(vect(subareas_selected))), ext(vect(subareas_selected)))\n",
    "\n",
    "        # Combine both: masked concentration + preserved land/coast layer\n",
    "        mask_mean_raster <- cover(mask_mean_raster, land_coast_mask)\n",
    "\n",
    "        return(list(mean_raster = mask_mean_raster, subareas_selected = subareas_selected))\n",
    "\n",
    "    } else {\n",
    "        bounds <- list(\n",
    "            N = as.numeric(numbers_only[letters_only == \"N\"]),\n",
    "            S = as.numeric(numbers_only[letters_only == \"S\"]),\n",
    "            W = as.numeric(numbers_only[letters_only == \"W\"]),\n",
    "            E = as.numeric(numbers_only[letters_only == \"E\"])\n",
    "        )\n",
    "        zone_extent <- ext(bounds$W, bounds$E, bounds$S, bounds$N)\n",
    "        projected_zone <- project(rast(ext = zone_extent, crs = \"EPSG:4326\"), \"EPSG:6932\")\n",
    "        area_vector <- NULL\n",
    "        extent_obj <- ext(projected_zone)\n",
    "        mask_mean_raster <- mask(crop(raster, extent_obj), extent_obj)\n",
    "\n",
    "        if (ASD) {\n",
    "            output_dir <- \"asd\"\n",
    "            dir.create(output_dir, showWarnings = FALSE)\n",
    "            base_url <- \"https://raw.githubusercontent.com/ccamlr/data/refs/tags/v0.5.0/geographical_data/asd/asd-shapefile-EPSG6932\"\n",
    "            extensions <- c(\".shp\", \".shx\", \".dbf\", \".prj\", \".cst\")\n",
    "\n",
    "            urls_asd <- paste0(base_url, extensions)\n",
    "            destfiles <- file.path(output_dir, paste0(\"asd-shapefile-EPSG6932\", extensions))\n",
    "\n",
    "            # Download each file and save to the output directory\n",
    "            for (i in seq_along(urls_asd)) {\n",
    "                download.file(urls_asd[i], destfiles[i], mode = \"wb\")\n",
    "            }\n",
    "\n",
    "            ASD <- st_read(\"asd/asd-shapefile-EPSG6932.shp\", quiet = TRUE)\n",
    "            subareas_selected <- ASD\n",
    "            return(list(mean_raster = mask_mean_raster, subareas_selected = subareas_selected))\n",
    "        }\n",
    "\n",
    "        return(mask_mean_raster)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4. MAIN ----\n",
    "# ==============================================================================\n",
    "\n",
    "count            <- 0\n",
    "\n",
    "if(is.null(year_ano)){\n",
    "    start_year = 1981\n",
    "    end_year   = 2010\n",
    "}else{\n",
    "    year_ano <- as.numeric(trimws(unlist(strsplit(year_ano, \"_\"))))\n",
    "    start_year = year_ano[1]\n",
    "    end_year   = year_ano[2]\n",
    "}\n",
    "\n",
    "default_areas <- c('883', '882', '481', '484', '482', '483', '5843a', '5843b','5852', '485', '486', '5841', '5842', '881', '5844a', '587','586', '5851', '5844b')\n",
    "\n",
    "letters_only <- str_extract(area_list, \"[A-Za-z]+\")\n",
    "numbers_only <- str_extract(area_list, \"-?\\\\d+\")\n",
    "\n",
    "for(i in seq_along(month_list)) {\n",
    "  paths <- create_directories(year_list[i], month_list[i])\n",
    "  month_index <- match(month_list[i], names(months_days))\n",
    "  \n",
    "  download_tiff_files(paths$tif_path, year_list[i], month_list[i], month_index)\n",
    "  mean_raster <- compute_monthly_mean(paths$tif_path, year_list[i], month_index)\n",
    "  \n",
    "\n",
    "  mask_return <- mask_subarea(area_list, mean_raster,asd_show)\n",
    "  if (is.list(mask_return)){\n",
    "    subareas_selected <- mask_return$subareas_selected\n",
    "    mean_raster_mask <- mask_return$mean_raster\n",
    "  }else{\n",
    "    subareas_selected <- FALSE\n",
    "    mean_raster_mask <- mask_return\n",
    "  }\n",
    "\n",
    "  \n",
    "  download_shapefiles(paths$zip_path, paths$shp_path, month_index)\n",
    "  polygons <- process_shapefiles(paths$shp_path)\n",
    "  color_breaks <- create_colors_and_breaks()\n",
    "  \n",
    "  if(count == 0){\n",
    "    raster_extent <- ext(mean_raster_mask)\n",
    "    w <- abs(raster_extent[2] - raster_extent[1]) / 10000\n",
    "    h <- abs(raster_extent[4] - raster_extent[3]) / 10000\n",
    "    if (png) {\n",
    "      png(\"outputs/collection/Fig3.png\", width = w * length(chose_list) * m, height = h * length(month_list) * m)   \n",
    "    } else {\n",
    "      pdf(\"outputs/collection/Fig3.pdf\", width = w * length(chose_list) * m, height = h * length(month_list) * m)\n",
    "        m <- m*100\n",
    "    }\n",
    "    par(mfrow = c(length(month_list), length(chose_list)))\n",
    "    count <- 1\n",
    "  }\n",
    "  \n",
    "  for(txt in chose_list){\n",
    "    if(txt == \"Concentration\"){\n",
    "      save_plot(mean_raster_mask, color_breaks$colors, color_breaks$breaks, polygons, year_list[i], month_list[i], subareas_selected,area_list, text_title,asd_show)\n",
    "    }\n",
    "    if(txt == \"Anomalies\"){\n",
    "        download_tiff_1981_2010(paths$tif_mean_path, start_year, end_year, month_index)\n",
    "        mean_1981_2010 <- compute_mean_raster_1981_2010(paths$tif_mean_path, month_index)\n",
    "        mean_1981_2010_mask <- mask_subarea(area_list, mean_1981_2010,asd_show)\n",
    "        if (is.list(mean_1981_2010_mask)) {\n",
    "          mean_1981_2010_raster <- mean_1981_2010_mask$mean_raster\n",
    "        } else {\n",
    "          mean_1981_2010_raster <- mean_1981_2010_mask\n",
    "        }\n",
    "        anomaly_data <- compute_anomaly(mean_raster_mask, mean_1981_2010_raster)\n",
    "        save_anomaly_plot(anomaly_data, mean_raster_mask, year_list[i], month_list[i], subareas_selected,area_list,asd_show)\n",
    "    }\n",
    "  }\n",
    "}\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d967f-76ba-4c6b-95e5-2b8f1bfcf676",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. LEGEND ----\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "path_conc <- \"outputs/Legend_Fig3_Concentration.png\"\n",
    "path_ano <- \"outputs/Legend_Fig3_Anomalies.png\"\n",
    "\n",
    "generate_legend <- function(zlim, breaks, colors, horizontal = TRUE, png_filename = \"legend.png\") {\n",
    "  # Define the limits of the legend\n",
    "  labels_legend <- format(zlim, nsmall = 2)  # Use zlim here for labels\n",
    "  n <- 5  # size factor\n",
    "\n",
    "  # Set image dimensions based on orientation\n",
    "  if (horizontal) {\n",
    "    png(filename = png_filename, width = 400 * n, height = 75 * n, bg = \"transparent\")\n",
    "    par(mar = c(2, 5, 2, 2))  # margins for horizontal legend\n",
    "  } else {\n",
    "    png(filename = png_filename, width = 75 * n, height = 400 * n, bg = \"transparent\")\n",
    "    par(mar = c(5, 2, 2, 5))  # margins for vertical legend\n",
    "  }\n",
    "\n",
    "  # Plot the legend only\n",
    "  fields::image.plot(\n",
    "    zlim = zlim,\n",
    "    breaks = breaks,\n",
    "    col = colors,\n",
    "    legend.only = TRUE,\n",
    "    horizontal = horizontal,\n",
    "    legend.width =  1.4 * n,\n",
    "    legend.shrink = 0.9,\n",
    "    legend.mar = 8,\n",
    "    axis.args = list(\n",
    "      at = zlim,  # Use zlim for tick positions\n",
    "      labels = labels_legend,  # Labels based on zlim\n",
    "      cex.axis = 2,\n",
    "      col.axis = \"black\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "  dev.off()\n",
    "}\n",
    "\n",
    "if(legend_chose != \"No legend\"){\n",
    "    if(legend_chose == \"Horizontal\"){\n",
    "        horizontal = TRUE        \n",
    "    }else{\n",
    "        horizontal = FALSE        \n",
    "    }\n",
    "    for(txt in chose_list){\n",
    "        if(txt == \"Concentration\"){\n",
    "            zlim <- seq(from = 0, to = 100, by = 10)\n",
    "            breaks <- seq(0,100,by=5)\n",
    "            colors <- color_breaks$colors\n",
    "            colors <- colors[1:(length(colors) - 2)]\n",
    "            generate_legend(zlim,breaks, colors, horizontal, png_filename = path_conc)    \n",
    "        }\n",
    "        if(txt == \"Anomalies\"){\n",
    "            zlim <- seq(from = -50, to = 50, by = 10)\n",
    "            breaks <- seq(-55,55,by=5)\n",
    "            colors <- setdiff(anomaly_data$col_fun,\"white\")\n",
    "            generate_legend(zlim,breaks, colors, horizontal, png_filename = path_ano)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "if (chose == \"Concentration_Anomalies\" ){     \n",
    "    \n",
    "    img_conc <- image_read(path_conc)\n",
    "    file.remove(path_conc)\n",
    "                \n",
    "    img_ano <- image_read(path_ano)\n",
    "    file.remove(path_ano)\n",
    "    \n",
    "    # Combiner horizontalement avec un petit espace entre les deux\n",
    "    combined <- image_append(c(img_conc, img_ano), stack = FALSE)\n",
    "    # Sauvegarder\n",
    "    image_write(combined, \"outputs/Legend_Fig3_Combined.png\")\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "rlang-kernel"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
